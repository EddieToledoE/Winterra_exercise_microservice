# üöÄ Gu√≠a de Despliegue en Producci√≥n

## üìã Requisitos Previos

- Docker instalado
- Docker Compose instalado
- Puerto 8001 disponible
- Acceso a los archivos de modelo (`models/modelo_isolation.pkl`, `models/scaler.pkl`)

## üê≥ Opci√≥n 1: Despliegue con Docker (Recomendado)

### Paso 1: Preparar el entorno
```bash
# Navegar al directorio del proyecto
cd anomaly_service

# Verificar que los archivos de modelo est√©n presentes
ls -la models/
# Deber√≠as ver: modelo_isolation.pkl y scaler.pkl
```

### Paso 2: Construir e iniciar el servicio
```bash
# Construir la imagen Docker
./deploy.sh build

# Iniciar el servicio
./deploy.sh start

# Verificar el estado
./deploy.sh status
```

### Paso 3: Verificar el despliegue
```bash
# Health check
curl http://localhost:8001/api/v1/anomaly/health

# Informaci√≥n del servicio
./deploy.sh info
```

## üîß Comandos √ötiles

```bash
# Ver logs en tiempo real
./deploy.sh logs

# Reiniciar el servicio
./deploy.sh restart

# Detener el servicio
./deploy.sh stop

# Limpiar recursos Docker
./deploy.sh cleanup
```

## üåê Acceso a la API

Una vez desplegado, la API estar√° disponible en:

- **Health Check**: `http://localhost:8001/api/v1/anomaly/health`
- **Documentaci√≥n**: `http://localhost:8001/docs`
- **Predicci√≥n (JSON est√°ndar)**: `POST http://localhost:8001/api/v1/anomaly/predict-real`
- **Predicci√≥n (MongoDB)**: `POST http://localhost:8001/api/v1/anomaly/predict`

## üîÑ Opci√≥n 2: Despliegue Manual (Sin Docker)

### Paso 1: Instalar dependencias
```bash
cd anomaly_service
pip install -r requirements.txt
```

### Paso 2: Configurar variables de entorno
```bash
export PYTHONPATH=/ruta/completa/a/anomaly_service
export PYTHONUNBUFFERED=1
```

### Paso 3: Ejecutar la aplicaci√≥n
```bash
# Opci√≥n 1: Directamente
python main.py

# Opci√≥n 2: Con uvicorn (recomendado para producci√≥n)
uvicorn main:app --host 0.0.0.0 --port 8001 --workers 1
```

## üîí Configuraci√≥n de Producci√≥n

### Variables de Entorno Recomendadas
```bash
# En el archivo .env o en el sistema
PYTHONPATH=/app
PYTHONUNBUFFERED=1
LOG_LEVEL=INFO
```

### Configuraci√≥n de Nginx (Opcional)
```nginx
server {
    listen 80;
    server_name tu-dominio.com;

    location /anomaly/ {
        proxy_pass http://localhost:8001/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

## üìä Monitoreo

### Health Check
```bash
curl -f http://localhost:8001/api/v1/anomaly/health
```

### Logs
```bash
# Con Docker
docker logs anomaly-detection-api

# Sin Docker
tail -f logs/app.log
```

### M√©tricas de Uso
- **Endpoint m√°s usado**: `/api/v1/anomaly/predict-real`
- **Tiempo de respuesta t√≠pico**: 200-500ms
- **Uso de memoria**: ~200MB por instancia

## üö® Troubleshooting

### Problema: Puerto 8001 ocupado
```bash
# Verificar qu√© est√° usando el puerto
lsof -i :8001

# Cambiar puerto en docker-compose.yml
ports:
  - "8002:8000"  # Cambiar 8001 por 8002
```

### Problema: Modelo no encontrado
```bash
# Verificar que los archivos est√©n en models/
ls -la models/

# Si faltan, copiarlos desde el directorio de entrenamiento
cp /ruta/a/modelo_isolation.pkl models/
cp /ruta/a/scaler.pkl models/
```

### Problema: Error de permisos
```bash
# Dar permisos al script de despliegue
chmod +x deploy.sh

# En sistemas Unix, puede necesitar sudo para Docker
sudo docker-compose up -d
```

## üîÑ Actualizaci√≥n en Producci√≥n

### Con Docker
```bash
# Detener el servicio
./deploy.sh stop

# Actualizar c√≥digo (git pull, etc.)

# Reconstruir e iniciar
./deploy.sh build
./deploy.sh start
```

### Sin Docker
```bash
# Detener el proceso
pkill -f "python main.py"

# Actualizar c√≥digo
git pull

# Reiniciar
python main.py
```

## üìà Escalabilidad

### M√∫ltiples Instancias
```bash
# En docker-compose.yml, agregar:
services:
  anomaly-detection-1:
    # ... configuraci√≥n
    ports:
      - "8001:8000"
  
  anomaly-detection-2:
    # ... configuraci√≥n
    ports:
      - "8002:8000"
```

### Load Balancer
```nginx
upstream anomaly_backend {
    server localhost:8001;
    server localhost:8002;
}

server {
    location /anomaly/ {
        proxy_pass http://anomaly_backend/;
    }
}
```

## üõ°Ô∏è Seguridad

### Firewall
```bash
# Permitir solo el puerto necesario
sudo ufw allow 8001
```

### Rate Limiting
```nginx
# En Nginx
limit_req_zone $binary_remote_addr zone=anomaly:10m rate=10r/s;
location /anomaly/ {
    limit_req zone=anomaly burst=20 nodelay;
    proxy_pass http://localhost:8001/;
}
```

## üìù Notas Importantes

1. **Puerto**: El servicio corre en puerto 8001 para no conflictuar con tu API de exercise
2. **Modelos**: Los archivos de modelo deben estar en `models/`
3. **Memoria**: El servicio usa ~200MB de RAM
4. **CPU**: Un core es suficiente para la mayor√≠a de casos
5. **Logs**: Los logs se muestran en stdout/stderr
6. **Restart**: El servicio se reinicia autom√°ticamente si falla

## üÜò Soporte

Si encuentras problemas:

1. Verificar logs: `./deploy.sh logs`
2. Verificar estado: `./deploy.sh status`
3. Reiniciar: `./deploy.sh restart`
4. Reconstruir: `./deploy.sh build && ./deploy.sh start` 